{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92d045e",
   "metadata": {},
   "source": [
    "# 사람의 손글씨 데이터인 MNIST를 이용해 Multi Layer Perceptron (MLP) 설계하기\n",
    "---\n",
    "- 0부터 9까지의 사람 손글씨 데이터인 MNIST를 이용해 기본적인 MLP 모델을 설계해보자. \n",
    "- MLP 모델을 설계하는 순서는 다음과 같음. \n",
    "\n",
    "1. 모듈 임포트하기\n",
    "2. 딥러닝 모델을 설계할 때 활용하는 장비 확인하기\n",
    "3. MNIST 데이터 다운로드하기 (train set / test set 분리하기)\n",
    "4. 데이터 확인하기 (1)\n",
    "5. 데이터 확인하기 (2)\n",
    "6. MLP(Multi Layer Perceptron) 모델 설계하기\n",
    "7. Optimizer, Objective Function 설정하기\n",
    "8. MLP 모델 학습을 진행하면서 학습 데이터에 대한 모델 성능을 확인하는 함수 정의하기\n",
    "9. 학습되는 과정 속에서 검증 데이터에 대한 모델의 성능을 확인하는 함수 정의하기\n",
    "10. MLP 학습을 실행하면서 train, test set의 Loss 및 test set accuracy 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7213f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. Module Import'''\n",
    "\n",
    "# 선형 대수와 관련된 함수를 쉽게 이용할 수 있는 모듈로, 대부분 파이썬 코드 스크립트에거 가장 자주 언급됨. \n",
    "import numpy as np\n",
    "\n",
    "# 함수 실행 결과 산출물에 대한 수치를 쉽게 이해할 수 있도록 시각화할 수 있는 외부 모듈\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 딥러닝 프레임워크 중 하나인 파이토치 기본 모듈\n",
    "import torch\n",
    "\n",
    "# PyTorch Module 중 딥러닝, 즉 인공 신경망 모델을 설계할 때 필요한 함수를 모아 놓은 모듈\n",
    "import torch.nn as nn\n",
    "\n",
    "# 'torch.nn' Module 중에서도 자주 이용되는 함수를 'F'로 지정\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 컴퓨터 비전 분야에서 자주 이용하는 'torchvision' 모듈 내 'transforms', 'datasets' 함수 import\n",
    "from torchvision import transforms, datasets    # (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f9c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version:  1.11.0 Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "'''2. 딥러닝 모델을 설계할 때 활용하는 장비 확인'''\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using Pytorch version: ', torch.__version__, 'Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7675c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32    # (1)\n",
    "EPOCHS = 10    # (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759018e",
   "metadata": {},
   "source": [
    "- 파이썬 코드내 하이퍼파라미터를 지정할 때 보통 영어 대문자로 표기함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18654f",
   "metadata": {},
   "source": [
    "(1) BATCH_SIZE: MLP 모델을 학습할 때 필요한 데이터 개수의 단위. \n",
    "- Mini-Batch 1개 단위에 대해 데이터가 32개로 구성되어 있는 것을 의미함. \n",
    "    - 좀 더 자세히 설명하면 MLP 모델을 학습할 때 32개의 데이터를 이용해 첫 번째로 학습하고, 그 다음 32개의 데이터를 이용해 두 번째로 학습함. \n",
    "    - 32개의 데이터로 1개의 Mini-Batch를 구성하고 있으며 1개의 Mini-Batch로 학습을 1회 진행함. \n",
    "    - 1개의 Mini-Batch를 이용해 학습하는 횟수를 'Iteration', 전체 데이터를 이용해 학습을 진행한 횟수를 'Epoch'이라 함. \n",
    "    - Epoch는 사용자가 정의하는 하이퍼파라미터임. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583223e",
   "metadata": {},
   "source": [
    "(2) EPOCHS: Mini-Batch 1개 단위로 Back Propagation을 이용해 MLP의 가중값을 업데이트하는데, Epoch는 존재하고 있는 Mini-Batch를 전부 이용하는 횟수를 의미함. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a464ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. MNIST 데이터 다운로드 (train set, test set 분리하기)'''\n",
    "\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",    # (1)\n",
    "                              train = True,\n",
    "                              download = True,\n",
    "                              transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\",    # (2)\n",
    "                             train = False,\n",
    "                             transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,    # (3)\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,    # (4)\n",
    "                                         batch_size = BATCH_SIZE,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047fc13",
   "metadata": {},
   "source": [
    "- 흔히 데이터를 외부에서 파이썬으로 불러와 이용함. \n",
    "- 주로 엑셀 파일로 데이터를 주고받으며 이를 쉽게 처리하기 위해 Pandas Module을 이용해 'pd.read_csv()'나 'pd.read_excel()' 함수를 이용하기도 함. \n",
    "- 이외에도 'PyTorch'에서 연구용으로 자주 이용하는 데이터를 쉽게 불러올 수 있도록 구현되어 있음. \n",
    "- 'torchvision' 내 'datasets' 함수를 이용해 데이터셋을 다운로드함. \n",
    "- MLP 모델을 학습하기 위해 이용하는 학습용 데이터셋과 학습이 진행된 이후 MLP 모델의 성능을 검증하기 위해 이용하는 검증용 데이터셋을 따로 분리해 설정함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a3305",
   "metadata": {},
   "source": [
    "(1), (2) MNIST 데이터셋 다운로드\n",
    "- root : 데이터가 저장될 장소 지정\n",
    "- train : 대상 데이터가 학습용 데이터인인지, 검증용 데이터인지 지정\n",
    "- download : 해당 데이터를 인터넷상에서 다운로드해 이용할 것인지 지정\n",
    "- transform : MNIST는 이미지 데이터임. 데이터를 다운로드할 때, 이미지 데이터에 대한 기본적인 전처리를 동시에 진행할 수 있음. \n",
    "    - 여기서는 'torch' 모듈로 설계한 MLP의 Input으로 이용되기 때문에 'ToTensor()' 메서드를 이용해 'tensor' 형태로 변경함. \n",
    "    - 또한 픽셀은 0\\~255 범위의 스칼라 값으로 구성되어 있는데, 이를 0\\~1 범위에서 정규화 과정이 진행됨. \n",
    "    - MLP 모델이 포함된 인공 신경망 모델은 Input 데이터 값의 크기가 커질수록 불안정하거나 과적합되는 방향으로 학습이 진행될 우려가 있기 때문에 정규화 과정을 이용해 Input으로 이용하는 것을 권장함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de6e9a",
   "metadata": {},
   "source": [
    "(3), (4) 다운로드한 MNIST 데이터셋을 Mini-Batch 단위로 분리해 지정함. \n",
    "- 여기서는 Mini-Batch 단위를 이용해 MLP 모델을 학습시킬 것이므로 Mini-Batch 별로 데이터를 묶어 단위를 맞추고자 함. \n",
    "- 이미지 데이터 1개 각각을 이용해 MLP 모델을 학습시키는 것이 아니라 이미지 데이터를 Batch Size만큼, 즉 32개만큼 묶어 1개의 Mini-Batch를 구성하는 것을 'DataLoader' 함수를 이용해 진행할 수 있음.\n",
    "    - dataset : Mini-Batch 단위로 할당하고자 하는 데이터셋을 지정\n",
    "    - batch_size : Mini-Batch 1개 단위를 구성하는 데이터의 개수를 지정함. \n",
    "    - shuffle : 데이터의 순서를 섞고자 할 때 이용함. 잘못된 방향으로 학습하는 것을 방지하기 위해 데이터 순서를 섞는 과정을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08e62b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([32, 1, 28, 28]) type:  torch.FloatTensor\n",
      "y_train:  torch.Size([32]) type:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "'''4. 데이터 확인하기 (1)'''\n",
    "for (X_train, y_train) in train_loader: \n",
    "    print('X_train: ', X_train.size(), 'type: ', X_train.type())\n",
    "    print('y_train: ', y_train.size(), 'type: ', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d6829",
   "metadata": {},
   "source": [
    "- 다운로드한 후 Mini-Batch 단위로 할당한 데이터의 개수와 형태 확인\n",
    "- X_train : 32개의 이미지 데이터가 1개의 Mini-Batch를 구성하고 있고 가로 28개, 세로 28개의 픽셀로 구성되어 있으며 채널이 1이므로 그레이스케일로 이루어진, 흑백으로 이루어진 이미지 데이터라는 것을 확인할 수 있음. \n",
    "- y_train : 32개의 이미지 데이터 각각에 label 값이 1개씩 존재하기 때문에 32개의 값을 갖고 있다는 것을 확인할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f77353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''5. 데이터 확인하기 (2)'''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap='gray_r')\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d9186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. MLP(Multi Layer Perceptron) 모델 설계하기'''\n",
    "\n",
    "# PyTorch Module 내에 딥러닝 모델 관련 기본 함수를 포함하고 있는 nn.Moudle 클래스를 상속받는 Net 클래스를 정의\n",
    "# nn.Module 클래스를 상속받았을 때 nn.Module 클래스의 함수를 그대로 이용할 수 있기 때문에 새로운 딥러닝 모델을 설계할 때 자주 이용됨. \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Net 클래스의 인스턴스를 생성했을 때 지니게 되는 성질을 정의해주는 메서드\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nn.Moudle 내에 있는 메서드를 상속받아 이용\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 첫 번째 Fully Connected Layer를 정의함. \n",
    "        # MNIST 데이터를 Input으로 사용하기 위해 28 * 28 * 1 크기의 노드 수를 설정한 후\n",
    "        # 두 번째 Fully Connected Layer의 노드 수를 512개로 설정할 것이기 때문에 Output의 노드 수는 512개로 설정함. \n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        \n",
    "        # 두 번재 Fully Connected Layer를 정의함. \n",
    "        # 첫 번째 Fully Connected Layer의 output 크기인 512 크기의 벡터 값을 Input을 사용하기 위해 노드 수를 512개로 설정하고\n",
    "        # 세 번재 Fully Connected Layer의 노드 수를 256으로 설정할 것이기 때문에 Output의 노드 수를 256개로 설정함. \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        \n",
    "        # 세 번째 Fully Connected Layer를 정의함. \n",
    "        # 두 번째 Fully Connected Layer의 Output 크기인 256 크기의 벡터 값을 Input으로 사용하기 위한 노드 수를 256개로 설정하고\n",
    "        # Output으로 사용하기 위한 노드 수를 10개로 설정함. \n",
    "        # 0부터 9까지 총 10가지 클래스를 표현하기위한 Label 값은 원-핫 인코딩으로 표현됨. \n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    \n",
    "    # Net 클래스를 이용해 설계한 MLP 모델의 Forward Propagation을 정의\n",
    "    # 즉, 설계한 MLP 모델에 데이터를 입력했을 때 Output을 계산하기까지의 과정을 나열한 것을 의미\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # MLP 모델은 1차원의 벡터 값을 입력으로 받을 수 있음. 하지만 MNIST 이미지 데이터는 크기가 28 * 28인 2차원 데이터임. \n",
    "        # 따라서 View 메서드를 이용해 784 크기의 1차원 데이터로 변환해 진행해야 함. \n",
    "        # 이를 2차원의 데이터를 1차원으로 펼친다고 표현하며 Flatten한다라고 표현하기도 함. \n",
    "        x = x.view(-1, 28 * 28)    # -1은 다른 차원으로부터 추론된다고 함. \n",
    "        \n",
    "        # __init__() method를 이용해 정의한 첫 번재 Fully Connected Layer에 1차원으로 펼친 이미지 데이터를 통과시킴. \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # PyTorch Module 중 인공 신경망(Neural Network) 설계에 유용한 함수를 모아놓은 torch.nn.functional 내에 정의된\n",
    "        # 비선형 함수인 sigmoid()를 이용해 두 번째 Fully Connected Layer의 Input으로 계산함. \n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # __init__() method를 이용해 정의한 두 번째 Fully Connected Layer에 앞에서 sigmoid()로 계산된 결과를 통과시킴. \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # torch.nn.functional 내의 log.softmax()를 이용해 최종 Output 계산\n",
    "        # 총 10가지 경우의 수 중 하나로 분류하는 일을 수행하기 때문에 softmax를 이용해 확률 값을 계산함. \n",
    "        # log_softmax()를 이용하는 이유는 MLP 모델이 Back Propagation 알고리즘을 이용해 학습을 진행할 때\n",
    "        # Loss 값에 대한 Gradient 값을 좀 더 원활하게 계산할 수 있기 때문임. \n",
    "        # Log 함수 그래프의 기울기가 부드럽게 변화하는 것을 상상해보면 직관적으로 이해할 수 있다고 함. \n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5000bf",
   "metadata": {},
   "source": [
    "- torch 모듈을 이용해 본격적으로 MLP를 설계하는 단계임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7208302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''7. Optimizer, Objective Function 설정하기'''\n",
    "\n",
    "model = Net().to(DEVICE)\n",
    "\n",
    "# Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 Optimizer 정의\n",
    "# 이 예제에서는 SGD 알고리즘을 이용해 파라미터를 업데이트할 때 반영될 LR을 0.01, \n",
    "# Optimizer의 관성을 나타내는 momentum을 0.5로 설정함. \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "\n",
    "# MLP 모델의 output 값과 계산될 Label 값은 Class를 표현하는 원-핫 인코딩 값임. \n",
    "# MLP 모델의 output 값과 원-핫 인코딩 값과의 Loss는 CrossEntropy를 이용해 계산하기 위해\n",
    "# criterion은 'nn.CrossEntropyLoss()'로 설정함. \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882207cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''8. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의'''\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    \n",
    "    # 기존에 정의한 MLP 모델을 학습 상태로 지정\n",
    "    model.train()\n",
    "    \n",
    "    # 기존에 정의한 'train_loader'에는 학습에 이용되는 이미지 데이터와 레이블 데이터가 Mini-Batch 단위로 묶여 저장되어 있음. \n",
    "    # 해당 'train_loader' 내에 Mini-Batch 단위로 저장된 데이터를 순서대로 이용해 MLP 모델을 학습\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        \n",
    "        # 기존에 정의한 장비에 이미지 데이터와 레이블 데이터를 할당할 경우, 과거에 이용한 Mini-Batch 내에 있는\n",
    "        # 이미지 데이터와 레이블 데이터를 바탕으로 계산된 Loss의 Gradient 값이 optimizer에 할당되어 있으므로\n",
    "        # optimizer의 Gradient를 초기화함. \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 장비에 할당한 이미지 데이터를 MLP 모델의 Input으로 이용해 Output을 계산\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 각 파라미터에 할당된 Gradient 값을 이용해 파라미터 값을 업데이트함. \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "            Epoch, batch_idx * len(image),\n",
    "            len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "            loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f6b0a",
   "metadata": {},
   "source": [
    "- MLP 모델을 설계했으므로 기존에 정의한 이미지 데이터와 레이블 데이터를 이용해 MLP 모델을 학습하는 train 함수를 정의함. \n",
    "- 다음은 학습의 진행 과정을 모니터링하기 위해 출력하는 코드임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d065c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의'''\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    \n",
    "    # 학습 과정 또는 학습이 완료된 MLP 모델을 학습 상태가 아닌, 평가 상태로 지정\n",
    "    model.eval()\n",
    "    \n",
    "    # 기존에 정의한 'test_loader' 내의 데이터를 이용해 Loss 값을 계산하기 위해 'test_loss'를 0으로 임시 설정\n",
    "    test_loss = 0\n",
    "    \n",
    "    # 학습 과정 또는 학습이 완료된 MLP 모델이 올바른 Class로 분류한 경우를 세기 위해 correct = 0으로 임시 설정\n",
    "    correct = 0\n",
    "    \n",
    "    # MLP 모델을 평가하는 단계에서는 Gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해\n",
    "    # 'torch.no_grad()' 메서드를 이용해 Gradient의 흐름을 억제함. \n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            \n",
    "            # MLP 모델의 Output 값은 크기가 10인 벡터임. \n",
    "            # 계산된 벡터 값 내 가장 큰 값인 위치에 대해 해당 위치에 대응하는 클래스로 예측했다고 판단함. \n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            \n",
    "            # MLP 모델이 최종으로 에측한 클래스 값과 실제 레이블이 의미하는 클래스가 맞으면 correct에 더해 올바르게 예측한 횟수를 저장\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "    \n",
    "    # 현재까지 계산된 'test_loss'의 값을 'test_loader' 내에 존재하는 Mini-Batch 개수만큼 나눠 평균 Loss 값으로 계산함. \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # 'test_loader' 데이터 중 얼마나 맞췄는지를 계산해 정확도를 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bd146",
   "metadata": {},
   "source": [
    "- MLP 모델 학습 과정 또는 학습이 완료된 상태에서 MLP 모델의 성능을 평가하기 위해 'evaluate' 함수를 정의함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58345d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000(0%)]\tTrain Loss: 2.349666\n",
      "Train Epoch: 1 [6400/60000(11%)]\tTrain Loss: 2.335147\n",
      "Train Epoch: 1 [12800/60000(21%)]\tTrain Loss: 2.288512\n",
      "Train Epoch: 1 [19200/60000(32%)]\tTrain Loss: 2.275110\n",
      "Train Epoch: 1 [25600/60000(43%)]\tTrain Loss: 2.240393\n",
      "Train Epoch: 1 [32000/60000(53%)]\tTrain Loss: 2.279598\n",
      "Train Epoch: 1 [38400/60000(64%)]\tTrain Loss: 2.354149\n",
      "Train Epoch: 1 [44800/60000(75%)]\tTrain Loss: 2.240101\n",
      "Train Epoch: 1 [51200/60000(85%)]\tTrain Loss: 2.245841\n",
      "Train Epoch: 1 [57600/60000(96%)]\tTrain Loss: 2.242896\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0696, \tTest Accuracy: 29.24 %\n",
      "\n",
      "Train Epoch: 2 [0/60000(0%)]\tTrain Loss: 2.199427\n",
      "Train Epoch: 2 [6400/60000(11%)]\tTrain Loss: 2.208917\n",
      "Train Epoch: 2 [12800/60000(21%)]\tTrain Loss: 2.101679\n",
      "Train Epoch: 2 [19200/60000(32%)]\tTrain Loss: 2.063266\n",
      "Train Epoch: 2 [25600/60000(43%)]\tTrain Loss: 1.990007\n",
      "Train Epoch: 2 [32000/60000(53%)]\tTrain Loss: 1.730914\n",
      "Train Epoch: 2 [38400/60000(64%)]\tTrain Loss: 1.783274\n",
      "Train Epoch: 2 [44800/60000(75%)]\tTrain Loss: 1.418045\n",
      "Train Epoch: 2 [51200/60000(85%)]\tTrain Loss: 1.440805\n",
      "Train Epoch: 2 [57600/60000(96%)]\tTrain Loss: 1.297151\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0396, \tTest Accuracy: 64.59 %\n",
      "\n",
      "Train Epoch: 3 [0/60000(0%)]\tTrain Loss: 1.221058\n",
      "Train Epoch: 3 [6400/60000(11%)]\tTrain Loss: 1.192724\n",
      "Train Epoch: 3 [12800/60000(21%)]\tTrain Loss: 1.048893\n",
      "Train Epoch: 3 [19200/60000(32%)]\tTrain Loss: 1.120891\n",
      "Train Epoch: 3 [25600/60000(43%)]\tTrain Loss: 0.771463\n",
      "Train Epoch: 3 [32000/60000(53%)]\tTrain Loss: 0.893068\n",
      "Train Epoch: 3 [38400/60000(64%)]\tTrain Loss: 1.034756\n",
      "Train Epoch: 3 [44800/60000(75%)]\tTrain Loss: 0.731479\n",
      "Train Epoch: 3 [51200/60000(85%)]\tTrain Loss: 0.621828\n",
      "Train Epoch: 3 [57600/60000(96%)]\tTrain Loss: 0.999309\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0235, \tTest Accuracy: 77.51 %\n",
      "\n",
      "Train Epoch: 4 [0/60000(0%)]\tTrain Loss: 0.684214\n",
      "Train Epoch: 4 [6400/60000(11%)]\tTrain Loss: 0.788156\n",
      "Train Epoch: 4 [12800/60000(21%)]\tTrain Loss: 0.752176\n",
      "Train Epoch: 4 [19200/60000(32%)]\tTrain Loss: 0.752848\n",
      "Train Epoch: 4 [25600/60000(43%)]\tTrain Loss: 0.555009\n",
      "Train Epoch: 4 [32000/60000(53%)]\tTrain Loss: 0.650440\n",
      "Train Epoch: 4 [38400/60000(64%)]\tTrain Loss: 0.502225\n",
      "Train Epoch: 4 [44800/60000(75%)]\tTrain Loss: 0.636039\n",
      "Train Epoch: 4 [51200/60000(85%)]\tTrain Loss: 0.507168\n",
      "Train Epoch: 4 [57600/60000(96%)]\tTrain Loss: 0.389091\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0174, \tTest Accuracy: 83.93 %\n",
      "\n",
      "Train Epoch: 5 [0/60000(0%)]\tTrain Loss: 0.587153\n",
      "Train Epoch: 5 [6400/60000(11%)]\tTrain Loss: 0.419753\n",
      "Train Epoch: 5 [12800/60000(21%)]\tTrain Loss: 0.563712\n",
      "Train Epoch: 5 [19200/60000(32%)]\tTrain Loss: 0.763236\n",
      "Train Epoch: 5 [25600/60000(43%)]\tTrain Loss: 0.386575\n",
      "Train Epoch: 5 [32000/60000(53%)]\tTrain Loss: 0.293969\n",
      "Train Epoch: 5 [38400/60000(64%)]\tTrain Loss: 0.537354\n",
      "Train Epoch: 5 [44800/60000(75%)]\tTrain Loss: 0.562661\n",
      "Train Epoch: 5 [51200/60000(85%)]\tTrain Loss: 0.668752\n",
      "Train Epoch: 5 [57600/60000(96%)]\tTrain Loss: 0.597820\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0145, \tTest Accuracy: 86.31 %\n",
      "\n",
      "Train Epoch: 6 [0/60000(0%)]\tTrain Loss: 0.257331\n",
      "Train Epoch: 6 [6400/60000(11%)]\tTrain Loss: 0.523516\n",
      "Train Epoch: 6 [12800/60000(21%)]\tTrain Loss: 0.625741\n",
      "Train Epoch: 6 [19200/60000(32%)]\tTrain Loss: 0.410777\n",
      "Train Epoch: 6 [25600/60000(43%)]\tTrain Loss: 0.478228\n",
      "Train Epoch: 6 [32000/60000(53%)]\tTrain Loss: 0.452374\n",
      "Train Epoch: 6 [38400/60000(64%)]\tTrain Loss: 0.288767\n",
      "Train Epoch: 6 [44800/60000(75%)]\tTrain Loss: 0.645467\n",
      "Train Epoch: 6 [51200/60000(85%)]\tTrain Loss: 0.201708\n",
      "Train Epoch: 6 [57600/60000(96%)]\tTrain Loss: 0.440952\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0132, \tTest Accuracy: 87.90 %\n",
      "\n",
      "Train Epoch: 7 [0/60000(0%)]\tTrain Loss: 0.537039\n",
      "Train Epoch: 7 [6400/60000(11%)]\tTrain Loss: 0.549928\n",
      "Train Epoch: 7 [12800/60000(21%)]\tTrain Loss: 0.357838\n",
      "Train Epoch: 7 [19200/60000(32%)]\tTrain Loss: 0.443000\n",
      "Train Epoch: 7 [25600/60000(43%)]\tTrain Loss: 0.822695\n",
      "Train Epoch: 7 [32000/60000(53%)]\tTrain Loss: 0.426870\n",
      "Train Epoch: 7 [38400/60000(64%)]\tTrain Loss: 0.351417\n",
      "Train Epoch: 7 [44800/60000(75%)]\tTrain Loss: 0.276570\n",
      "Train Epoch: 7 [51200/60000(85%)]\tTrain Loss: 0.312845\n",
      "Train Epoch: 7 [57600/60000(96%)]\tTrain Loss: 0.576304\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0121, \tTest Accuracy: 88.86 %\n",
      "\n",
      "Train Epoch: 8 [0/60000(0%)]\tTrain Loss: 0.743824\n",
      "Train Epoch: 8 [6400/60000(11%)]\tTrain Loss: 0.496154\n",
      "Train Epoch: 8 [12800/60000(21%)]\tTrain Loss: 0.659295\n",
      "Train Epoch: 8 [19200/60000(32%)]\tTrain Loss: 0.335607\n",
      "Train Epoch: 8 [25600/60000(43%)]\tTrain Loss: 0.278517\n",
      "Train Epoch: 8 [32000/60000(53%)]\tTrain Loss: 0.440423\n",
      "Train Epoch: 8 [38400/60000(64%)]\tTrain Loss: 0.515521\n",
      "Train Epoch: 8 [44800/60000(75%)]\tTrain Loss: 0.155752\n",
      "Train Epoch: 8 [51200/60000(85%)]\tTrain Loss: 0.389438\n",
      "Train Epoch: 8 [57600/60000(96%)]\tTrain Loss: 0.327786\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0115, \tTest Accuracy: 89.29 %\n",
      "\n",
      "Train Epoch: 9 [0/60000(0%)]\tTrain Loss: 0.709951\n",
      "Train Epoch: 9 [6400/60000(11%)]\tTrain Loss: 0.358302\n",
      "Train Epoch: 9 [12800/60000(21%)]\tTrain Loss: 0.202021\n",
      "Train Epoch: 9 [19200/60000(32%)]\tTrain Loss: 0.375782\n",
      "Train Epoch: 9 [25600/60000(43%)]\tTrain Loss: 0.443619\n",
      "Train Epoch: 9 [32000/60000(53%)]\tTrain Loss: 0.299459\n",
      "Train Epoch: 9 [38400/60000(64%)]\tTrain Loss: 0.215517\n",
      "Train Epoch: 9 [44800/60000(75%)]\tTrain Loss: 0.290549\n",
      "Train Epoch: 9 [51200/60000(85%)]\tTrain Loss: 0.480115\n",
      "Train Epoch: 9 [57600/60000(96%)]\tTrain Loss: 0.227249\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0110, \tTest Accuracy: 89.74 %\n",
      "\n",
      "Train Epoch: 10 [0/60000(0%)]\tTrain Loss: 0.357891\n",
      "Train Epoch: 10 [6400/60000(11%)]\tTrain Loss: 0.499054\n",
      "Train Epoch: 10 [12800/60000(21%)]\tTrain Loss: 0.209282\n",
      "Train Epoch: 10 [19200/60000(32%)]\tTrain Loss: 0.245322\n",
      "Train Epoch: 10 [25600/60000(43%)]\tTrain Loss: 0.176433\n",
      "Train Epoch: 10 [32000/60000(53%)]\tTrain Loss: 0.448848\n",
      "Train Epoch: 10 [38400/60000(64%)]\tTrain Loss: 0.366765\n",
      "Train Epoch: 10 [44800/60000(75%)]\tTrain Loss: 0.477198\n",
      "Train Epoch: 10 [51200/60000(85%)]\tTrain Loss: 0.236107\n",
      "Train Epoch: 10 [57600/60000(96%)]\tTrain Loss: 0.386722\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0106, \tTest Accuracy: 90.30 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''10. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy를 확인하기'''\n",
    "\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    \n",
    "    # 정의한 train 함수 실행\n",
    "    # model은 기존에 정의한 MLP 모델, train_loader는 학습 데이터, optimizer는 SGD,\n",
    "    # log_interval은 학습이 진행되면서 Mini-Batch의 Index를 이용해 과정을 모니터링할 수 있도록 출력하는 것을 의미함. \n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    \n",
    "    # 각 Epoch별로 출력되는 Loss 값과 accuracy 값을 계산함. \n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".\n",
    "         format(Epoch, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
