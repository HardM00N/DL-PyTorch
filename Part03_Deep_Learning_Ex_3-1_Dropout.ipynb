{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92d045e",
   "metadata": {},
   "source": [
    "# 사람의 손글씨 데이터인 MNIST를 이용해 Multi Layer Perceptron (MLP) 설계할 때 Dropout 적용해보기\n",
    "---\n",
    "- 신경망이 지니고 있는 단점인 과적합과 Gradient Vanishing을 완화시킬 수 있는 여러 알고리즘이 나오기 시작하면서 딥러닝이 발전하게 됨. \n",
    "- Dropout은 신경망의 학습 과정 중 Layer의 노드를 랜덤하게 Drop함으로써 Generalization 효과를 가져오게 하는 테크닉임. \n",
    "- 신경망을 비롯한 많은 머신러닝 알고리즘은 행렬로 연산됨. Input Data, Weight, Hidden Layer 모두 행렬임. \n",
    "- Dropout을 적용한다는 것은 Weight Matrix에 랜덤하게 일부 Column에 0을 집어넣어 연산을 한다고 이해하면 됨. \n",
    "- Dropout을 적용할 때는 얼마나 랜덤하게 Dropout 기법을 적용할 것인지에 대한 확률 값을 지정해야 하고, 이는 Input Layer와 Hidden Layer에도 적용할 수 있음. \n",
    "- 또한 Epoch마다 랜덤하게 Dropout함. 이런 방식으로 계속 연산하면 과적합을 어느 정도 방지하는 효과를 가져옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7213f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. Module Import'''\n",
    "\n",
    "# 선형 대수와 관련된 함수를 쉽게 이용할 수 있는 모듈로, 대부분 파이썬 코드 스크립트에거 가장 자주 언급됨. \n",
    "import numpy as np\n",
    "\n",
    "# 함수 실행 결과 산출물에 대한 수치를 쉽게 이해할 수 있도록 시각화할 수 있는 외부 모듈\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 딥러닝 프레임워크 중 하나인 파이토치 기본 모듈\n",
    "import torch\n",
    "\n",
    "# PyTorch Module 중 딥러닝, 즉 인공 신경망 모델을 설계할 때 필요한 함수를 모아 놓은 모듈\n",
    "import torch.nn as nn\n",
    "\n",
    "# 'torch.nn' Module 중에서도 자주 이용되는 함수를 'F'로 지정\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 컴퓨터 비전 분야에서 자주 이용하는 'torchvision' 모듈 내 'transforms', 'datasets' 함수 import\n",
    "from torchvision import transforms, datasets    # (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f9c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version:  1.11.0 Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "'''2. 딥러닝 모델을 설계할 때 활용하는 장비 확인'''\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using Pytorch version: ', torch.__version__, 'Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7675c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32    # (1)\n",
    "EPOCHS = 10    # (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759018e",
   "metadata": {},
   "source": [
    "- 파이썬 코드내 하이퍼파라미터를 지정할 때 보통 영어 대문자로 표기함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18654f",
   "metadata": {},
   "source": [
    "(1) BATCH_SIZE: MLP 모델을 학습할 때 필요한 데이터 개수의 단위. \n",
    "- Mini-Batch 1개 단위에 대해 데이터가 32개로 구성되어 있는 것을 의미함. \n",
    "    - 좀 더 자세히 설명하면 MLP 모델을 학습할 때 32개의 데이터를 이용해 첫 번째로 학습하고, 그 다음 32개의 데이터를 이용해 두 번째로 학습함. \n",
    "    - 32개의 데이터로 1개의 Mini-Batch를 구성하고 있으며 1개의 Mini-Batch로 학습을 1회 진행함. \n",
    "    - 1개의 Mini-Batch를 이용해 학습하는 횟수를 'Iteration', 전체 데이터를 이용해 학습을 진행한 횟수를 'Epoch'이라 함. \n",
    "    - Epoch는 사용자가 정의하는 하이퍼파라미터임. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583223e",
   "metadata": {},
   "source": [
    "(2) EPOCHS: Mini-Batch 1개 단위로 Back Propagation을 이용해 MLP의 가중값을 업데이트하는데, Epoch는 존재하고 있는 Mini-Batch를 전부 이용하는 횟수를 의미함. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a464ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. MNIST 데이터 다운로드 (train set, test set 분리하기)'''\n",
    "\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",    # (1)\n",
    "                              train = True,\n",
    "                              download = True,\n",
    "                              transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\",    # (2)\n",
    "                             train = False,\n",
    "                             transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,    # (3)\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,    # (4)\n",
    "                                         batch_size = BATCH_SIZE,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047fc13",
   "metadata": {},
   "source": [
    "- 흔히 데이터를 외부에서 파이썬으로 불러와 이용함. \n",
    "- 주로 엑셀 파일로 데이터를 주고받으며 이를 쉽게 처리하기 위해 Pandas Module을 이용해 'pd.read_csv()'나 'pd.read_excel()' 함수를 이용하기도 함. \n",
    "- 이외에도 'PyTorch'에서 연구용으로 자주 이용하는 데이터를 쉽게 불러올 수 있도록 구현되어 있음. \n",
    "- 'torchvision' 내 'datasets' 함수를 이용해 데이터셋을 다운로드함. \n",
    "- MLP 모델을 학습하기 위해 이용하는 학습용 데이터셋과 학습이 진행된 이후 MLP 모델의 성능을 검증하기 위해 이용하는 검증용 데이터셋을 따로 분리해 설정함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a3305",
   "metadata": {},
   "source": [
    "(1), (2) MNIST 데이터셋 다운로드\n",
    "- root : 데이터가 저장될 장소 지정\n",
    "- train : 대상 데이터가 학습용 데이터인인지, 검증용 데이터인지 지정\n",
    "- download : 해당 데이터를 인터넷상에서 다운로드해 이용할 것인지 지정\n",
    "- transform : MNIST는 이미지 데이터임. 데이터를 다운로드할 때, 이미지 데이터에 대한 기본적인 전처리를 동시에 진행할 수 있음. \n",
    "    - 여기서는 'torch' 모듈로 설계한 MLP의 Input으로 이용되기 때문에 'ToTensor()' 메서드를 이용해 'tensor' 형태로 변경함. \n",
    "    - 또한 픽셀은 0\\~255 범위의 스칼라 값으로 구성되어 있는데, 이를 0\\~1 범위에서 정규화 과정이 진행됨. \n",
    "    - MLP 모델이 포함된 인공 신경망 모델은 Input 데이터 값의 크기가 커질수록 불안정하거나 과적합되는 방향으로 학습이 진행될 우려가 있기 때문에 정규화 과정을 이용해 Input으로 이용하는 것을 권장함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de6e9a",
   "metadata": {},
   "source": [
    "(3), (4) 다운로드한 MNIST 데이터셋을 Mini-Batch 단위로 분리해 지정함. \n",
    "- 여기서는 Mini-Batch 단위를 이용해 MLP 모델을 학습시킬 것이므로 Mini-Batch 별로 데이터를 묶어 단위를 맞추고자 함. \n",
    "- 이미지 데이터 1개 각각을 이용해 MLP 모델을 학습시키는 것이 아니라 이미지 데이터를 Batch Size만큼, 즉 32개만큼 묶어 1개의 Mini-Batch를 구성하는 것을 'DataLoader' 함수를 이용해 진행할 수 있음.\n",
    "    - dataset : Mini-Batch 단위로 할당하고자 하는 데이터셋을 지정\n",
    "    - batch_size : Mini-Batch 1개 단위를 구성하는 데이터의 개수를 지정함. \n",
    "    - shuffle : 데이터의 순서를 섞고자 할 때 이용함. 잘못된 방향으로 학습하는 것을 방지하기 위해 데이터 순서를 섞는 과정을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08e62b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([32, 1, 28, 28]) type:  torch.FloatTensor\n",
      "y_train:  torch.Size([32]) type:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "'''4. 데이터 확인하기 (1)'''\n",
    "for (X_train, y_train) in train_loader: \n",
    "    print('X_train: ', X_train.size(), 'type: ', X_train.type())\n",
    "    print('y_train: ', y_train.size(), 'type: ', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d6829",
   "metadata": {},
   "source": [
    "- 다운로드한 후 Mini-Batch 단위로 할당한 데이터의 개수와 형태 확인\n",
    "- X_train : 32개의 이미지 데이터가 1개의 Mini-Batch를 구성하고 있고 가로 28개, 세로 28개의 픽셀로 구성되어 있으며 채널이 1이므로 그레이스케일로 이루어진, 흑백으로 이루어진 이미지 데이터라는 것을 확인할 수 있음. \n",
    "- y_train : 32개의 이미지 데이터 각각에 label 값이 1개씩 존재하기 때문에 32개의 값을 갖고 있다는 것을 확인할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f77353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''5. 데이터 확인하기 (2)'''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap='gray_r')\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d9186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. MLP(Multi Layer Perceptron) 모델 설계하기'''\n",
    "\n",
    "# PyTorch Module 내에 딥러닝 모델 관련 기본 함수를 포함하고 있는 nn.Moudle 클래스를 상속받는 Net 클래스를 정의\n",
    "# nn.Module 클래스를 상속받았을 때 nn.Module 클래스의 함수를 그대로 이용할 수 있기 때문에 새로운 딥러닝 모델을 설계할 때 자주 이용됨. \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    # Net 클래스의 인스턴스를 생성했을 때 지니게 되는 성질을 정의해주는 메서드\n",
    "    def __init__(self):\n",
    "        \n",
    "        # nn.Moudle 내에 있는 메서드를 상속받아 이용\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 첫 번째 Fully Connected Layer를 정의함. \n",
    "        # MNIST 데이터를 Input으로 사용하기 위해 28 * 28 * 1 크기의 노드 수를 설정한 후\n",
    "        # 두 번째 Fully Connected Layer의 노드 수를 512개로 설정할 것이기 때문에 Output의 노드 수는 512개로 설정함. \n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        \n",
    "        # 두 번재 Fully Connected Layer를 정의함. \n",
    "        # 첫 번째 Fully Connected Layer의 output 크기인 512 크기의 벡터 값을 Input을 사용하기 위해 노드 수를 512개로 설정하고\n",
    "        # 세 번재 Fully Connected Layer의 노드 수를 256으로 설정할 것이기 때문에 Output의 노드 수를 256개로 설정함. \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        \n",
    "        # 세 번째 Fully Connected Layer를 정의함. \n",
    "        # 두 번째 Fully Connected Layer의 Output 크기인 256 크기의 벡터 값을 Input으로 사용하기 위한 노드 수를 256개로 설정하고\n",
    "        # Output으로 사용하기 위한 노드 수를 10개로 설정함. \n",
    "        # 0부터 9까지 총 10가지 클래스를 표현하기위한 Label 값은 원-핫 인코딩으로 표현됨. \n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "        # 몇 퍼센트의 노드에 대해 가중값을 계산하지 않을 것인지를 명시해주는 부분\n",
    "        self.dropout_prob = 0.5\n",
    "    \n",
    "    # Net 클래스를 이용해 설계한 MLP 모델의 Forward Propagation을 정의\n",
    "    # 즉, 설계한 MLP 모델에 데이터를 입력했을 때 Output을 계산하기까지의 과정을 나열한 것을 의미\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # MLP 모델은 1차원의 벡터 값을 입력으로 받을 수 있음. 하지만 MNIST 이미지 데이터는 크기가 28 * 28인 2차원 데이터임. \n",
    "        # 따라서 View 메서드를 이용해 784 크기의 1차원 데이터로 변환해 진행해야 함. \n",
    "        # 이를 2차원의 데이터를 1차원으로 펼친다고 표현하며 Flatten한다라고 표현하기도 함. \n",
    "        x = x.view(-1, 28 * 28)    # -1은 다른 차원으로부터 추론된다고 함. \n",
    "        \n",
    "        # __init__() method를 이용해 정의한 첫 번재 Fully Connected Layer에 1차원으로 펼친 이미지 데이터를 통과시킴. \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # PyTorch Module 중 인공 신경망(Neural Network) 설계에 유용한 함수를 모아놓은 torch.nn.functional 내에 정의된\n",
    "        # 비선형 함수인 sigmoid()를 이용해 두 번째 Fully Connected Layer의 Input으로 계산함. \n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # 각 sigmoid() 함수의 결고값에 대해 Droppout을 적용하는 부분\n",
    "        # training = self.training은 학습 상태일 때와 검증 상태에 따라 다르게 적용되기 위해 존재하는 파라미터임. \n",
    "        # Dropout은 학습 과정 속에서 랜덤으로 노드를 선택해 가중값이 업데이트되지 않도록 조정하지만, \n",
    "        # 평가 과정 속에서는 모든 노드를 이용해 Output을 계산하기 때문에 학습 상태와 검증 상태에서 다르게 적용되어야 함. \n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob) \n",
    "        \n",
    "        # __init__() method를 이용해 정의한 두 번째 Fully Connected Layer에 앞에서 sigmoid()로 계산된 결과를 통과시킴. \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = F.sigmoid(x)\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob) \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # torch.nn.functional 내의 log.softmax()를 이용해 최종 Output 계산\n",
    "        # 총 10가지 경우의 수 중 하나로 분류하는 일을 수행하기 때문에 softmax를 이용해 확률 값을 계산함. \n",
    "        # log_softmax()를 이용하는 이유는 MLP 모델이 Back Propagation 알고리즘을 이용해 학습을 진행할 때\n",
    "        # Loss 값에 대한 Gradient 값을 좀 더 원활하게 계산할 수 있기 때문임. \n",
    "        # Log 함수 그래프의 기울기가 부드럽게 변화하는 것을 상상해보면 직관적으로 이해할 수 있다고 함. \n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5000bf",
   "metadata": {},
   "source": [
    "- torch 모듈을 이용해 본격적으로 MLP를 설계하는 단계임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7208302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''7. Optimizer, Objective Function 설정하기'''\n",
    "\n",
    "model = Net().to(DEVICE)\n",
    "\n",
    "# Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 Optimizer 정의\n",
    "# 이 예제에서는 SGD 알고리즘을 이용해 파라미터를 업데이트할 때 반영될 LR을 0.01, \n",
    "# Optimizer의 관성을 나타내는 momentum을 0.5로 설정함. \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "\n",
    "# MLP 모델의 output 값과 계산될 Label 값은 Class를 표현하는 원-핫 인코딩 값임. \n",
    "# MLP 모델의 output 값과 원-핫 인코딩 값과의 Loss는 CrossEntropy를 이용해 계산하기 위해\n",
    "# criterion은 'nn.CrossEntropyLoss()'로 설정함. \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882207cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''8. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의'''\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    \n",
    "    # 기존에 정의한 MLP 모델을 학습 상태로 지정\n",
    "    model.train()\n",
    "    \n",
    "    # 기존에 정의한 'train_loader'에는 학습에 이용되는 이미지 데이터와 레이블 데이터가 Mini-Batch 단위로 묶여 저장되어 있음. \n",
    "    # 해당 'train_loader' 내에 Mini-Batch 단위로 저장된 데이터를 순서대로 이용해 MLP 모델을 학습\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        \n",
    "        # 기존에 정의한 장비에 이미지 데이터와 레이블 데이터를 할당할 경우, 과거에 이용한 Mini-Batch 내에 있는\n",
    "        # 이미지 데이터와 레이블 데이터를 바탕으로 계산된 Loss의 Gradient 값이 optimizer에 할당되어 있으므로\n",
    "        # optimizer의 Gradient를 초기화함. \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 장비에 할당한 이미지 데이터를 MLP 모델의 Input으로 이용해 Output을 계산\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 각 파라미터에 할당된 Gradient 값을 이용해 파라미터 값을 업데이트함. \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "            Epoch, batch_idx * len(image),\n",
    "            len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "            loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f6b0a",
   "metadata": {},
   "source": [
    "- MLP 모델을 설계했으므로 기존에 정의한 이미지 데이터와 레이블 데이터를 이용해 MLP 모델을 학습하는 train 함수를 정의함. \n",
    "- 다음은 학습의 진행 과정을 모니터링하기 위해 출력하는 코드임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d065c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의'''\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    \n",
    "    # 학습 과정 또는 학습이 완료된 MLP 모델을 학습 상태가 아닌, 평가 상태로 지정\n",
    "    model.eval()\n",
    "    \n",
    "    # 기존에 정의한 'test_loader' 내의 데이터를 이용해 Loss 값을 계산하기 위해 'test_loss'를 0으로 임시 설정\n",
    "    test_loss = 0\n",
    "    \n",
    "    # 학습 과정 또는 학습이 완료된 MLP 모델이 올바른 Class로 분류한 경우를 세기 위해 correct = 0으로 임시 설정\n",
    "    correct = 0\n",
    "    \n",
    "    # MLP 모델을 평가하는 단계에서는 Gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해\n",
    "    # 'torch.no_grad()' 메서드를 이용해 Gradient의 흐름을 억제함. \n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            \n",
    "            # MLP 모델의 Output 값은 크기가 10인 벡터임. \n",
    "            # 계산된 벡터 값 내 가장 큰 값인 위치에 대해 해당 위치에 대응하는 클래스로 예측했다고 판단함. \n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            \n",
    "            # MLP 모델이 최종으로 에측한 클래스 값과 실제 레이블이 의미하는 클래스가 맞으면 correct에 더해 올바르게 예측한 횟수를 저장\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "    \n",
    "    # 현재까지 계산된 'test_loss'의 값을 'test_loader' 내에 존재하는 Mini-Batch 개수만큼 나눠 평균 Loss 값으로 계산함. \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # 'test_loader' 데이터 중 얼마나 맞췄는지를 계산해 정확도를 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bd146",
   "metadata": {},
   "source": [
    "- MLP 모델 학습 과정 또는 학습이 완료된 상태에서 MLP 모델의 성능을 평가하기 위해 'evaluate' 함수를 정의함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58345d99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000(0%)]\tTrain Loss: 2.365543\n",
      "Train Epoch: 1 [6400/60000(11%)]\tTrain Loss: 2.350654\n",
      "Train Epoch: 1 [12800/60000(21%)]\tTrain Loss: 2.340778\n",
      "Train Epoch: 1 [19200/60000(32%)]\tTrain Loss: 2.368758\n",
      "Train Epoch: 1 [25600/60000(43%)]\tTrain Loss: 2.339110\n",
      "Train Epoch: 1 [32000/60000(53%)]\tTrain Loss: 2.281949\n",
      "Train Epoch: 1 [38400/60000(64%)]\tTrain Loss: 2.299628\n",
      "Train Epoch: 1 [44800/60000(75%)]\tTrain Loss: 2.265604\n",
      "Train Epoch: 1 [51200/60000(85%)]\tTrain Loss: 2.269531\n",
      "Train Epoch: 1 [57600/60000(96%)]\tTrain Loss: 2.291203\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0714, \tTest Accuracy: 14.84 %\n",
      "\n",
      "Train Epoch: 2 [0/60000(0%)]\tTrain Loss: 2.262770\n",
      "Train Epoch: 2 [6400/60000(11%)]\tTrain Loss: 2.244600\n",
      "Train Epoch: 2 [12800/60000(21%)]\tTrain Loss: 2.295525\n",
      "Train Epoch: 2 [19200/60000(32%)]\tTrain Loss: 2.246093\n",
      "Train Epoch: 2 [25600/60000(43%)]\tTrain Loss: 2.234591\n",
      "Train Epoch: 2 [32000/60000(53%)]\tTrain Loss: 2.235462\n",
      "Train Epoch: 2 [38400/60000(64%)]\tTrain Loss: 2.253095\n",
      "Train Epoch: 2 [44800/60000(75%)]\tTrain Loss: 2.248621\n",
      "Train Epoch: 2 [51200/60000(85%)]\tTrain Loss: 2.231120\n",
      "Train Epoch: 2 [57600/60000(96%)]\tTrain Loss: 2.075219\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0638, \tTest Accuracy: 40.09 %\n",
      "\n",
      "Train Epoch: 3 [0/60000(0%)]\tTrain Loss: 2.033777\n",
      "Train Epoch: 3 [6400/60000(11%)]\tTrain Loss: 2.070605\n",
      "Train Epoch: 3 [12800/60000(21%)]\tTrain Loss: 1.892608\n",
      "Train Epoch: 3 [19200/60000(32%)]\tTrain Loss: 1.708201\n",
      "Train Epoch: 3 [25600/60000(43%)]\tTrain Loss: 1.691057\n",
      "Train Epoch: 3 [32000/60000(53%)]\tTrain Loss: 1.544654\n",
      "Train Epoch: 3 [38400/60000(64%)]\tTrain Loss: 1.480936\n",
      "Train Epoch: 3 [44800/60000(75%)]\tTrain Loss: 1.483289\n",
      "Train Epoch: 3 [51200/60000(85%)]\tTrain Loss: 1.259701\n",
      "Train Epoch: 3 [57600/60000(96%)]\tTrain Loss: 1.382714\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0369, \tTest Accuracy: 62.23 %\n",
      "\n",
      "Train Epoch: 4 [0/60000(0%)]\tTrain Loss: 1.129281\n",
      "Train Epoch: 4 [6400/60000(11%)]\tTrain Loss: 1.430174\n",
      "Train Epoch: 4 [12800/60000(21%)]\tTrain Loss: 1.187969\n",
      "Train Epoch: 4 [19200/60000(32%)]\tTrain Loss: 1.485048\n",
      "Train Epoch: 4 [25600/60000(43%)]\tTrain Loss: 1.068740\n",
      "Train Epoch: 4 [32000/60000(53%)]\tTrain Loss: 0.996442\n",
      "Train Epoch: 4 [38400/60000(64%)]\tTrain Loss: 1.251910\n",
      "Train Epoch: 4 [44800/60000(75%)]\tTrain Loss: 1.133345\n",
      "Train Epoch: 4 [51200/60000(85%)]\tTrain Loss: 1.131615\n",
      "Train Epoch: 4 [57600/60000(96%)]\tTrain Loss: 1.129513\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0274, \tTest Accuracy: 69.66 %\n",
      "\n",
      "Train Epoch: 5 [0/60000(0%)]\tTrain Loss: 1.378222\n",
      "Train Epoch: 5 [6400/60000(11%)]\tTrain Loss: 1.045044\n",
      "Train Epoch: 5 [12800/60000(21%)]\tTrain Loss: 0.987489\n",
      "Train Epoch: 5 [19200/60000(32%)]\tTrain Loss: 0.933439\n",
      "Train Epoch: 5 [25600/60000(43%)]\tTrain Loss: 0.831406\n",
      "Train Epoch: 5 [32000/60000(53%)]\tTrain Loss: 0.943126\n",
      "Train Epoch: 5 [38400/60000(64%)]\tTrain Loss: 0.951988\n",
      "Train Epoch: 5 [44800/60000(75%)]\tTrain Loss: 0.851813\n",
      "Train Epoch: 5 [51200/60000(85%)]\tTrain Loss: 0.647265\n",
      "Train Epoch: 5 [57600/60000(96%)]\tTrain Loss: 0.618928\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0237, \tTest Accuracy: 76.07 %\n",
      "\n",
      "Train Epoch: 6 [0/60000(0%)]\tTrain Loss: 1.126031\n",
      "Train Epoch: 6 [6400/60000(11%)]\tTrain Loss: 0.868516\n",
      "Train Epoch: 6 [12800/60000(21%)]\tTrain Loss: 0.908451\n",
      "Train Epoch: 6 [19200/60000(32%)]\tTrain Loss: 0.855626\n",
      "Train Epoch: 6 [25600/60000(43%)]\tTrain Loss: 0.864647\n",
      "Train Epoch: 6 [32000/60000(53%)]\tTrain Loss: 0.497857\n",
      "Train Epoch: 6 [38400/60000(64%)]\tTrain Loss: 0.785728\n",
      "Train Epoch: 6 [44800/60000(75%)]\tTrain Loss: 0.643687\n",
      "Train Epoch: 6 [51200/60000(85%)]\tTrain Loss: 0.773345\n",
      "Train Epoch: 6 [57600/60000(96%)]\tTrain Loss: 0.639736\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0209, \tTest Accuracy: 79.56 %\n",
      "\n",
      "Train Epoch: 7 [0/60000(0%)]\tTrain Loss: 0.715765\n",
      "Train Epoch: 7 [6400/60000(11%)]\tTrain Loss: 0.561013\n",
      "Train Epoch: 7 [12800/60000(21%)]\tTrain Loss: 0.708735\n",
      "Train Epoch: 7 [19200/60000(32%)]\tTrain Loss: 0.839573\n",
      "Train Epoch: 7 [25600/60000(43%)]\tTrain Loss: 1.092598\n",
      "Train Epoch: 7 [32000/60000(53%)]\tTrain Loss: 0.884739\n",
      "Train Epoch: 7 [38400/60000(64%)]\tTrain Loss: 0.885749\n",
      "Train Epoch: 7 [44800/60000(75%)]\tTrain Loss: 0.818010\n",
      "Train Epoch: 7 [51200/60000(85%)]\tTrain Loss: 0.718912\n",
      "Train Epoch: 7 [57600/60000(96%)]\tTrain Loss: 0.478809\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0183, \tTest Accuracy: 82.53 %\n",
      "\n",
      "Train Epoch: 8 [0/60000(0%)]\tTrain Loss: 0.357679\n",
      "Train Epoch: 8 [6400/60000(11%)]\tTrain Loss: 0.949028\n",
      "Train Epoch: 8 [12800/60000(21%)]\tTrain Loss: 0.718306\n",
      "Train Epoch: 8 [19200/60000(32%)]\tTrain Loss: 0.979853\n",
      "Train Epoch: 8 [25600/60000(43%)]\tTrain Loss: 0.792176\n",
      "Train Epoch: 8 [32000/60000(53%)]\tTrain Loss: 0.850422\n",
      "Train Epoch: 8 [38400/60000(64%)]\tTrain Loss: 0.682012\n",
      "Train Epoch: 8 [44800/60000(75%)]\tTrain Loss: 0.742952\n",
      "Train Epoch: 8 [51200/60000(85%)]\tTrain Loss: 0.545723\n",
      "Train Epoch: 8 [57600/60000(96%)]\tTrain Loss: 0.800554\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0161, \tTest Accuracy: 85.15 %\n",
      "\n",
      "Train Epoch: 9 [0/60000(0%)]\tTrain Loss: 0.693204\n",
      "Train Epoch: 9 [6400/60000(11%)]\tTrain Loss: 0.387503\n",
      "Train Epoch: 9 [12800/60000(21%)]\tTrain Loss: 0.541771\n",
      "Train Epoch: 9 [19200/60000(32%)]\tTrain Loss: 0.469857\n",
      "Train Epoch: 9 [25600/60000(43%)]\tTrain Loss: 0.520495\n",
      "Train Epoch: 9 [32000/60000(53%)]\tTrain Loss: 0.602968\n",
      "Train Epoch: 9 [38400/60000(64%)]\tTrain Loss: 0.829222\n",
      "Train Epoch: 9 [44800/60000(75%)]\tTrain Loss: 1.255218\n",
      "Train Epoch: 9 [51200/60000(85%)]\tTrain Loss: 0.659138\n",
      "Train Epoch: 9 [57600/60000(96%)]\tTrain Loss: 0.556196\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0147, \tTest Accuracy: 86.16 %\n",
      "\n",
      "Train Epoch: 10 [0/60000(0%)]\tTrain Loss: 0.712169\n",
      "Train Epoch: 10 [6400/60000(11%)]\tTrain Loss: 0.613488\n",
      "Train Epoch: 10 [12800/60000(21%)]\tTrain Loss: 0.669007\n",
      "Train Epoch: 10 [19200/60000(32%)]\tTrain Loss: 0.484129\n",
      "Train Epoch: 10 [25600/60000(43%)]\tTrain Loss: 0.721737\n",
      "Train Epoch: 10 [32000/60000(53%)]\tTrain Loss: 0.714469\n",
      "Train Epoch: 10 [38400/60000(64%)]\tTrain Loss: 0.627023\n",
      "Train Epoch: 10 [44800/60000(75%)]\tTrain Loss: 0.678176\n",
      "Train Epoch: 10 [51200/60000(85%)]\tTrain Loss: 0.810708\n",
      "Train Epoch: 10 [57600/60000(96%)]\tTrain Loss: 0.578693\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0138, \tTest Accuracy: 87.19 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''10. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy를 확인하기'''\n",
    "\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    \n",
    "    # 정의한 train 함수 실행\n",
    "    # model은 기존에 정의한 MLP 모델, train_loader는 학습 데이터, optimizer는 SGD,\n",
    "    # log_interval은 학습이 진행되면서 Mini-Batch의 Index를 이용해 과정을 모니터링할 수 있도록 출력하는 것을 의미함. \n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    \n",
    "    # 각 Epoch별로 출력되는 Loss 값과 accuracy 값을 계산함. \n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".\n",
    "         format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2214027",
   "metadata": {},
   "source": [
    "- 이론상 Dropout을 적용했을 때 일반화가 강해져 Test Accuracy가 높아지는 결과가 기대되지만, 이는 학습 데이터셋과 검증 데이터셋의 피처 및 레이블의 분포 간 많은 차이가 있을 때 유효하게 작용함. \n",
    "- MNIST 데이터셋은 학습 데이터와 검증 데이터 간 많은 차이가 발생하지 않기 때문에 오히려 성능이 조금 하락할 수도 있음. \n",
    "- 하지만 Epoch을 늘려 추가로 학습을 진행하면 성능이 좋아지는 경향이 있음. \n",
    "- Dropout은 보통 ReLU() 비선형 함수와 잘 어울림. \n",
    "- 바로 다음 예제에서 비선형 함수를 sigmoid()에서 ReLU()로 변경했을 때 Dropout의 효과를 살펴볼 예정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fff686",
   "metadata": {},
   "source": [
    "## Reference\n",
    "---\n",
    "- 파이썬 딥러닝 파이토치 - 이경택, 방성수, 안상준"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
