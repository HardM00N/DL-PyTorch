{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5699d9a",
   "metadata": {},
   "source": [
    "# Activation 함수\n",
    "---\n",
    "- Activation 함수는 어떤 신호를 입력받아 이를 적절히 처리해 출력해주는 함수를 의미하고, MLP에서 기본적으로 시그모이드 함수를 사용함. \n",
    "- 그런데 Back Propagation 과정 중에 시그모이드를 미분한 값을 계속 곱해주면서 Gradient 값이 앞 단의 Layer로 올수록 0으로 수렴하는 현상이 발생\n",
    "- 이를 'Gradient Vanishing'이라 하며 이는 Hidden Layer가 깊어질수록 심해지기 때문에 Hidden Layer를 깊게 쌓아 복잡한 모델을 만들 수 있는 장점이 의미가 없게 됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df028f",
   "metadata": {},
   "source": [
    "## ReLU 함수\n",
    "---\n",
    "- ReLU(Rectified Linear Unit) 함수는 기존의 시그모이드 함수와 같은 비선형 활성 함수가 지니고 있는 문제를 어느 정도 해결함. \n",
    "- 활성 함수 ReLU는 $f(x) = max(0, x)$와 같이 정의되고 아래 그림과 같이 나타낼 수 있음. \n",
    "- 입력 값이 0 이상이면 이 값을 그대로 출력하고 0 이하이면 0으로 출력하는 함수임. \n",
    "- 이 활성 함수가 시그모이드 함수에 비해 좋은 이유는 이 활성 함수를 미분할 때 입력 값이 0 이상인 부분은 기울기가 1, 0 이하인 부분은 0이 되기 때문임. \n",
    "- 즉, Back Propagation 과정 중 곱해지는 Acvitation 미분값이 0 또는 1이 되기 때문에 아예 없애거나 완전히 살리는 것으로 해석할 수 있음. \n",
    "- 이를 통해 Hidden Layer가 깊어져도 Gradient Vanishing이 일어나는 것을 완화시키며 Layer를 깊게 쌓아 복잡한 모형을 만들 수 있게 되었음. \n",
    "- ReLU 함수의 변형 함수도 많이 나왔는데, Leaky ReLU, ELU, prametric ReLU, SELU, SERLU 등 다양한 Acivation 함수가 나오고 있음. 하지만 모든 Task에 대해 이 활성 함수가 항상 가장 좋다고는 할 수 없음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d045e",
   "metadata": {},
   "source": [
    "# 사람의 손글씨 데이터인 MNIST를 이용해 Multi Layer Perceptron (MLP) 설계할 때 Dropout 적용해보기\n",
    "---\n",
    "- 0부터 9까지의 사람 손글씨 데이터인 MNIST를 이용해 기본적인 MLP 모델을 설계해보자. \n",
    "- MLP 모델을 설계하는 순서는 다음과 같음. \n",
    "\n",
    "1. 모듈 임포트하기\n",
    "2. 딥러닝 모델을 설계할 때 활용하는 장비 확인하기\n",
    "3. MNIST 데이터 다운로드하기 (train set / test set 분리하기)\n",
    "4. 데이터 확인하기 (1)\n",
    "5. 데이터 확인하기 (2)\n",
    "6. MLP(Multi Layer Perceptron) 모델 설계하기\n",
    "7. Optimizer, Objective Function 설정하기\n",
    "8. MLP 모델 학습을 진행하면서 학습 데이터에 대한 모델 성능을 확인하는 함수 정의하기\n",
    "9. 학습되는 과정 속에서 검증 데이터에 대한 모델의 성능을 확인하는 함수 정의하기\n",
    "10. MLP 학습을 실행하면서 train, test set의 Loss 및 test set accuracy 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7213f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. Module Import'''\n",
    "\n",
    "# 선형 대수와 관련된 함수를 쉽게 이용할 수 있는 모듈로, 대부분 파이썬 코드 스크립트에거 가장 자주 언급됨. \n",
    "import numpy as np\n",
    "\n",
    "# 함수 실행 결과 산출물에 대한 수치를 쉽게 이해할 수 있도록 시각화할 수 있는 외부 모듈\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 딥러닝 프레임워크 중 하나인 파이토치 기본 모듈\n",
    "import torch\n",
    "\n",
    "# PyTorch Module 중 딥러닝, 즉 인공 신경망 모델을 설계할 때 필요한 함수를 모아 놓은 모듈\n",
    "import torch.nn as nn\n",
    "\n",
    "# 'torch.nn' Module 중에서도 자주 이용되는 함수를 'F'로 지정\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 컴퓨터 비전 분야에서 자주 이용하는 'torchvision' 모듈 내 'transforms', 'datasets' 함수 import\n",
    "from torchvision import transforms, datasets    # (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f9c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version:  1.11.0 Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "'''2. 딥러닝 모델을 설계할 때 활용하는 장비 확인'''\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using Pytorch version: ', torch.__version__, 'Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7675c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32    # (1)\n",
    "EPOCHS = 10    # (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759018e",
   "metadata": {},
   "source": [
    "- 파이썬 코드내 하이퍼파라미터를 지정할 때 보통 영어 대문자로 표기함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18654f",
   "metadata": {},
   "source": [
    "(1) BATCH_SIZE: MLP 모델을 학습할 때 필요한 데이터 개수의 단위. \n",
    "- Mini-Batch 1개 단위에 대해 데이터가 32개로 구성되어 있는 것을 의미함. \n",
    "    - 좀 더 자세히 설명하면 MLP 모델을 학습할 때 32개의 데이터를 이용해 첫 번째로 학습하고, 그 다음 32개의 데이터를 이용해 두 번째로 학습함. \n",
    "    - 32개의 데이터로 1개의 Mini-Batch를 구성하고 있으며 1개의 Mini-Batch로 학습을 1회 진행함. \n",
    "    - 1개의 Mini-Batch를 이용해 학습하는 횟수를 'Iteration', 전체 데이터를 이용해 학습을 진행한 횟수를 'Epoch'이라 함. \n",
    "    - Epoch는 사용자가 정의하는 하이퍼파라미터임. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583223e",
   "metadata": {},
   "source": [
    "(2) EPOCHS: Mini-Batch 1개 단위로 Back Propagation을 이용해 MLP의 가중값을 업데이트하는데, Epoch는 존재하고 있는 Mini-Batch를 전부 이용하는 횟수를 의미함. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a464ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. MNIST 데이터 다운로드 (train set, test set 분리하기)'''\n",
    "\n",
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",    # (1)\n",
    "                              train = True,\n",
    "                              download = True,\n",
    "                              transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\",    # (2)\n",
    "                             train = False,\n",
    "                             transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,    # (3)\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,    # (4)\n",
    "                                         batch_size = BATCH_SIZE,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047fc13",
   "metadata": {},
   "source": [
    "- 흔히 데이터를 외부에서 파이썬으로 불러와 이용함. \n",
    "- 주로 엑셀 파일로 데이터를 주고받으며 이를 쉽게 처리하기 위해 Pandas Module을 이용해 'pd.read_csv()'나 'pd.read_excel()' 함수를 이용하기도 함. \n",
    "- 이외에도 'PyTorch'에서 연구용으로 자주 이용하는 데이터를 쉽게 불러올 수 있도록 구현되어 있음. \n",
    "- 'torchvision' 내 'datasets' 함수를 이용해 데이터셋을 다운로드함. \n",
    "- MLP 모델을 학습하기 위해 이용하는 학습용 데이터셋과 학습이 진행된 이후 MLP 모델의 성능을 검증하기 위해 이용하는 검증용 데이터셋을 따로 분리해 설정함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08a3305",
   "metadata": {},
   "source": [
    "(1), (2) MNIST 데이터셋 다운로드\n",
    "- root : 데이터가 저장될 장소 지정\n",
    "- train : 대상 데이터가 학습용 데이터인인지, 검증용 데이터인지 지정\n",
    "- download : 해당 데이터를 인터넷상에서 다운로드해 이용할 것인지 지정\n",
    "- transform : MNIST는 이미지 데이터임. 데이터를 다운로드할 때, 이미지 데이터에 대한 기본적인 전처리를 동시에 진행할 수 있음. \n",
    "    - 여기서는 'torch' 모듈로 설계한 MLP의 Input으로 이용되기 때문에 'ToTensor()' 메서드를 이용해 'tensor' 형태로 변경함. \n",
    "    - 또한 픽셀은 0\\~255 범위의 스칼라 값으로 구성되어 있는데, 이를 0\\~1 범위에서 정규화 과정이 진행됨. \n",
    "    - MLP 모델이 포함된 인공 신경망 모델은 Input 데이터 값의 크기가 커질수록 불안정하거나 과적합되는 방향으로 학습이 진행될 우려가 있기 때문에 정규화 과정을 이용해 Input으로 이용하는 것을 권장함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de6e9a",
   "metadata": {},
   "source": [
    "(3), (4) 다운로드한 MNIST 데이터셋을 Mini-Batch 단위로 분리해 지정함. \n",
    "- 여기서는 Mini-Batch 단위를 이용해 MLP 모델을 학습시킬 것이므로 Mini-Batch 별로 데이터를 묶어 단위를 맞추고자 함. \n",
    "- 이미지 데이터 1개 각각을 이용해 MLP 모델을 학습시키는 것이 아니라 이미지 데이터를 Batch Size만큼, 즉 32개만큼 묶어 1개의 Mini-Batch를 구성하는 것을 'DataLoader' 함수를 이용해 진행할 수 있음.\n",
    "    - dataset : Mini-Batch 단위로 할당하고자 하는 데이터셋을 지정\n",
    "    - batch_size : Mini-Batch 1개 단위를 구성하는 데이터의 개수를 지정함. \n",
    "    - shuffle : 데이터의 순서를 섞고자 할 때 이용함. 잘못된 방향으로 학습하는 것을 방지하기 위해 데이터 순서를 섞는 과정을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08e62b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  torch.Size([32, 1, 28, 28]) type:  torch.FloatTensor\n",
      "y_train:  torch.Size([32]) type:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "'''4. 데이터 확인하기 (1)'''\n",
    "for (X_train, y_train) in train_loader: \n",
    "    print('X_train: ', X_train.size(), 'type: ', X_train.type())\n",
    "    print('y_train: ', y_train.size(), 'type: ', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d6829",
   "metadata": {},
   "source": [
    "- 다운로드한 후 Mini-Batch 단위로 할당한 데이터의 개수와 형태 확인\n",
    "- X_train : 32개의 이미지 데이터가 1개의 Mini-Batch를 구성하고 있고 가로 28개, 세로 28개의 픽셀로 구성되어 있으며 채널이 1이므로 그레이스케일로 이루어진, 흑백으로 이루어진 이미지 데이터라는 것을 확인할 수 있음. \n",
    "- y_train : 32개의 이미지 데이터 각각에 label 값이 1개씩 존재하기 때문에 32개의 값을 갖고 있다는 것을 확인할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f77353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''5. 데이터 확인하기 (2)'''\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap='gray_r')\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d9186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. MLP(Multi Layer Perceptron) 모델 설계하기'''\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.dropout_prob = 0.5\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # ReLU() 함수는 0 미만은 0으로, 양수 값은 그대로 반영하는 비선형 함수로\n",
    "        # Gradient를 빠르게 계산하고 Back Propagation을 효과적으로 이용할 수 있음. \n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob)        \n",
    "        x = self.fc2(x)      \n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training = self.training, p = self.dropout_prob) \n",
    "        x = self.fc3(x)       \n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5000bf",
   "metadata": {},
   "source": [
    "- torch 모듈을 이용해 본격적으로 MLP를 설계하는 단계임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7208302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''7. Optimizer, Objective Function 설정하기'''\n",
    "\n",
    "model = Net().to(DEVICE)\n",
    "\n",
    "# Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 Optimizer 정의\n",
    "# 이 예제에서는 SGD 알고리즘을 이용해 파라미터를 업데이트할 때 반영될 LR을 0.01, \n",
    "# Optimizer의 관성을 나타내는 momentum을 0.5로 설정함. \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "\n",
    "# MLP 모델의 output 값과 계산될 Label 값은 Class를 표현하는 원-핫 인코딩 값임. \n",
    "# MLP 모델의 output 값과 원-핫 인코딩 값과의 Loss는 CrossEntropy를 이용해 계산하기 위해\n",
    "# criterion은 'nn.CrossEntropyLoss()'로 설정함. \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882207cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''8. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의'''\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    \n",
    "    # 기존에 정의한 MLP 모델을 학습 상태로 지정\n",
    "    model.train()\n",
    "    \n",
    "    # 기존에 정의한 'train_loader'에는 학습에 이용되는 이미지 데이터와 레이블 데이터가 Mini-Batch 단위로 묶여 저장되어 있음. \n",
    "    # 해당 'train_loader' 내에 Mini-Batch 단위로 저장된 데이터를 순서대로 이용해 MLP 모델을 학습\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        \n",
    "        # 기존에 정의한 장비에 이미지 데이터와 레이블 데이터를 할당할 경우, 과거에 이용한 Mini-Batch 내에 있는\n",
    "        # 이미지 데이터와 레이블 데이터를 바탕으로 계산된 Loss의 Gradient 값이 optimizer에 할당되어 있으므로\n",
    "        # optimizer의 Gradient를 초기화함. \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 장비에 할당한 이미지 데이터를 MLP 모델의 Input으로 이용해 Output을 계산\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 각 파라미터에 할당된 Gradient 값을 이용해 파라미터 값을 업데이트함. \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "            Epoch, batch_idx * len(image),\n",
    "            len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
    "            loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f6b0a",
   "metadata": {},
   "source": [
    "- MLP 모델을 설계했으므로 기존에 정의한 이미지 데이터와 레이블 데이터를 이용해 MLP 모델을 학습하는 train 함수를 정의함. \n",
    "- 다음은 학습의 진행 과정을 모니터링하기 위해 출력하는 코드임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d065c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의'''\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    \n",
    "    # 학습 과정 또는 학습이 완료된 MLP 모델을 학습 상태가 아닌, 평가 상태로 지정\n",
    "    model.eval()\n",
    "    \n",
    "    # 기존에 정의한 'test_loader' 내의 데이터를 이용해 Loss 값을 계산하기 위해 'test_loss'를 0으로 임시 설정\n",
    "    test_loss = 0\n",
    "    \n",
    "    # 학습 과정 또는 학습이 완료된 MLP 모델이 올바른 Class로 분류한 경우를 세기 위해 correct = 0으로 임시 설정\n",
    "    correct = 0\n",
    "    \n",
    "    # MLP 모델을 평가하는 단계에서는 Gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해\n",
    "    # 'torch.no_grad()' 메서드를 이용해 Gradient의 흐름을 억제함. \n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            \n",
    "            # MLP 모델의 Output 값은 크기가 10인 벡터임. \n",
    "            # 계산된 벡터 값 내 가장 큰 값인 위치에 대해 해당 위치에 대응하는 클래스로 예측했다고 판단함. \n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            \n",
    "            # MLP 모델이 최종으로 에측한 클래스 값과 실제 레이블이 의미하는 클래스가 맞으면 correct에 더해 올바르게 예측한 횟수를 저장\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "            \n",
    "    \n",
    "    # 현재까지 계산된 'test_loss'의 값을 'test_loader' 내에 존재하는 Mini-Batch 개수만큼 나눠 평균 Loss 값으로 계산함. \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # 'test_loader' 데이터 중 얼마나 맞췄는지를 계산해 정확도를 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bd146",
   "metadata": {},
   "source": [
    "- MLP 모델 학습 과정 또는 학습이 완료된 상태에서 MLP 모델의 성능을 평가하기 위해 'evaluate' 함수를 정의함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58345d99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000(0%)]\tTrain Loss: 2.299145\n",
      "Train Epoch: 1 [6400/60000(11%)]\tTrain Loss: 2.094563\n",
      "Train Epoch: 1 [12800/60000(21%)]\tTrain Loss: 1.097151\n",
      "Train Epoch: 1 [19200/60000(32%)]\tTrain Loss: 0.992451\n",
      "Train Epoch: 1 [25600/60000(43%)]\tTrain Loss: 0.730551\n",
      "Train Epoch: 1 [32000/60000(53%)]\tTrain Loss: 0.456168\n",
      "Train Epoch: 1 [38400/60000(64%)]\tTrain Loss: 0.861474\n",
      "Train Epoch: 1 [44800/60000(75%)]\tTrain Loss: 0.397430\n",
      "Train Epoch: 1 [51200/60000(85%)]\tTrain Loss: 0.360101\n",
      "Train Epoch: 1 [57600/60000(96%)]\tTrain Loss: 0.310602\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0102, \tTest Accuracy: 90.98 %\n",
      "\n",
      "Train Epoch: 2 [0/60000(0%)]\tTrain Loss: 0.503390\n",
      "Train Epoch: 2 [6400/60000(11%)]\tTrain Loss: 0.441242\n",
      "Train Epoch: 2 [12800/60000(21%)]\tTrain Loss: 0.316254\n",
      "Train Epoch: 2 [19200/60000(32%)]\tTrain Loss: 0.239400\n",
      "Train Epoch: 2 [25600/60000(43%)]\tTrain Loss: 0.478040\n",
      "Train Epoch: 2 [32000/60000(53%)]\tTrain Loss: 0.463966\n",
      "Train Epoch: 2 [38400/60000(64%)]\tTrain Loss: 0.325203\n",
      "Train Epoch: 2 [44800/60000(75%)]\tTrain Loss: 0.191253\n",
      "Train Epoch: 2 [51200/60000(85%)]\tTrain Loss: 0.316167\n",
      "Train Epoch: 2 [57600/60000(96%)]\tTrain Loss: 0.147180\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0070, \tTest Accuracy: 93.40 %\n",
      "\n",
      "Train Epoch: 3 [0/60000(0%)]\tTrain Loss: 0.359962\n",
      "Train Epoch: 3 [6400/60000(11%)]\tTrain Loss: 0.241401\n",
      "Train Epoch: 3 [12800/60000(21%)]\tTrain Loss: 0.149659\n",
      "Train Epoch: 3 [19200/60000(32%)]\tTrain Loss: 0.228386\n",
      "Train Epoch: 3 [25600/60000(43%)]\tTrain Loss: 0.099313\n",
      "Train Epoch: 3 [32000/60000(53%)]\tTrain Loss: 0.198956\n",
      "Train Epoch: 3 [38400/60000(64%)]\tTrain Loss: 0.274629\n",
      "Train Epoch: 3 [44800/60000(75%)]\tTrain Loss: 0.565422\n",
      "Train Epoch: 3 [51200/60000(85%)]\tTrain Loss: 0.390577\n",
      "Train Epoch: 3 [57600/60000(96%)]\tTrain Loss: 0.122793\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0054, \tTest Accuracy: 94.90 %\n",
      "\n",
      "Train Epoch: 4 [0/60000(0%)]\tTrain Loss: 0.252288\n",
      "Train Epoch: 4 [6400/60000(11%)]\tTrain Loss: 0.206330\n",
      "Train Epoch: 4 [12800/60000(21%)]\tTrain Loss: 0.407689\n",
      "Train Epoch: 4 [19200/60000(32%)]\tTrain Loss: 0.137406\n",
      "Train Epoch: 4 [25600/60000(43%)]\tTrain Loss: 0.147984\n",
      "Train Epoch: 4 [32000/60000(53%)]\tTrain Loss: 0.195938\n",
      "Train Epoch: 4 [38400/60000(64%)]\tTrain Loss: 0.221272\n",
      "Train Epoch: 4 [44800/60000(75%)]\tTrain Loss: 0.191621\n",
      "Train Epoch: 4 [51200/60000(85%)]\tTrain Loss: 0.137596\n",
      "Train Epoch: 4 [57600/60000(96%)]\tTrain Loss: 0.103356\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0046, \tTest Accuracy: 95.67 %\n",
      "\n",
      "Train Epoch: 5 [0/60000(0%)]\tTrain Loss: 0.090909\n",
      "Train Epoch: 5 [6400/60000(11%)]\tTrain Loss: 0.257254\n",
      "Train Epoch: 5 [12800/60000(21%)]\tTrain Loss: 0.193302\n",
      "Train Epoch: 5 [19200/60000(32%)]\tTrain Loss: 0.137852\n",
      "Train Epoch: 5 [25600/60000(43%)]\tTrain Loss: 0.214378\n",
      "Train Epoch: 5 [32000/60000(53%)]\tTrain Loss: 0.149049\n",
      "Train Epoch: 5 [38400/60000(64%)]\tTrain Loss: 0.096554\n",
      "Train Epoch: 5 [44800/60000(75%)]\tTrain Loss: 0.111099\n",
      "Train Epoch: 5 [51200/60000(85%)]\tTrain Loss: 0.200665\n",
      "Train Epoch: 5 [57600/60000(96%)]\tTrain Loss: 0.135957\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0039, \tTest Accuracy: 96.03 %\n",
      "\n",
      "Train Epoch: 6 [0/60000(0%)]\tTrain Loss: 0.197645\n",
      "Train Epoch: 6 [6400/60000(11%)]\tTrain Loss: 0.058269\n",
      "Train Epoch: 6 [12800/60000(21%)]\tTrain Loss: 0.090916\n",
      "Train Epoch: 6 [19200/60000(32%)]\tTrain Loss: 0.186080\n",
      "Train Epoch: 6 [25600/60000(43%)]\tTrain Loss: 0.060915\n",
      "Train Epoch: 6 [32000/60000(53%)]\tTrain Loss: 0.166759\n",
      "Train Epoch: 6 [38400/60000(64%)]\tTrain Loss: 0.081021\n",
      "Train Epoch: 6 [44800/60000(75%)]\tTrain Loss: 0.186703\n",
      "Train Epoch: 6 [51200/60000(85%)]\tTrain Loss: 0.268642\n",
      "Train Epoch: 6 [57600/60000(96%)]\tTrain Loss: 0.163278\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0034, \tTest Accuracy: 96.66 %\n",
      "\n",
      "Train Epoch: 7 [0/60000(0%)]\tTrain Loss: 0.050054\n",
      "Train Epoch: 7 [6400/60000(11%)]\tTrain Loss: 0.440716\n",
      "Train Epoch: 7 [12800/60000(21%)]\tTrain Loss: 0.187949\n",
      "Train Epoch: 7 [19200/60000(32%)]\tTrain Loss: 0.034157\n",
      "Train Epoch: 7 [25600/60000(43%)]\tTrain Loss: 0.121371\n",
      "Train Epoch: 7 [32000/60000(53%)]\tTrain Loss: 0.041187\n",
      "Train Epoch: 7 [38400/60000(64%)]\tTrain Loss: 0.298942\n",
      "Train Epoch: 7 [44800/60000(75%)]\tTrain Loss: 0.111629\n",
      "Train Epoch: 7 [51200/60000(85%)]\tTrain Loss: 0.337294\n",
      "Train Epoch: 7 [57600/60000(96%)]\tTrain Loss: 0.072735\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0032, \tTest Accuracy: 96.87 %\n",
      "\n",
      "Train Epoch: 8 [0/60000(0%)]\tTrain Loss: 0.057821\n",
      "Train Epoch: 8 [6400/60000(11%)]\tTrain Loss: 0.027143\n",
      "Train Epoch: 8 [12800/60000(21%)]\tTrain Loss: 0.170469\n",
      "Train Epoch: 8 [19200/60000(32%)]\tTrain Loss: 0.103587\n",
      "Train Epoch: 8 [25600/60000(43%)]\tTrain Loss: 0.110944\n",
      "Train Epoch: 8 [32000/60000(53%)]\tTrain Loss: 0.075416\n",
      "Train Epoch: 8 [38400/60000(64%)]\tTrain Loss: 0.419851\n",
      "Train Epoch: 8 [44800/60000(75%)]\tTrain Loss: 0.130081\n",
      "Train Epoch: 8 [51200/60000(85%)]\tTrain Loss: 0.070830\n",
      "Train Epoch: 8 [57600/60000(96%)]\tTrain Loss: 0.087632\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0029, \tTest Accuracy: 97.10 %\n",
      "\n",
      "Train Epoch: 9 [0/60000(0%)]\tTrain Loss: 0.076911\n",
      "Train Epoch: 9 [6400/60000(11%)]\tTrain Loss: 0.298852\n",
      "Train Epoch: 9 [12800/60000(21%)]\tTrain Loss: 0.149367\n",
      "Train Epoch: 9 [19200/60000(32%)]\tTrain Loss: 0.229904\n",
      "Train Epoch: 9 [25600/60000(43%)]\tTrain Loss: 0.151938\n",
      "Train Epoch: 9 [32000/60000(53%)]\tTrain Loss: 0.368021\n",
      "Train Epoch: 9 [38400/60000(64%)]\tTrain Loss: 0.216247\n",
      "Train Epoch: 9 [44800/60000(75%)]\tTrain Loss: 0.035186\n",
      "Train Epoch: 9 [51200/60000(85%)]\tTrain Loss: 0.083267\n",
      "Train Epoch: 9 [57600/60000(96%)]\tTrain Loss: 0.074392\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0028, \tTest Accuracy: 97.40 %\n",
      "\n",
      "Train Epoch: 10 [0/60000(0%)]\tTrain Loss: 0.112694\n",
      "Train Epoch: 10 [6400/60000(11%)]\tTrain Loss: 0.161835\n",
      "Train Epoch: 10 [12800/60000(21%)]\tTrain Loss: 0.056231\n",
      "Train Epoch: 10 [19200/60000(32%)]\tTrain Loss: 0.078153\n",
      "Train Epoch: 10 [25600/60000(43%)]\tTrain Loss: 0.167263\n",
      "Train Epoch: 10 [32000/60000(53%)]\tTrain Loss: 0.072799\n",
      "Train Epoch: 10 [38400/60000(64%)]\tTrain Loss: 0.030017\n",
      "Train Epoch: 10 [44800/60000(75%)]\tTrain Loss: 0.491279\n",
      "Train Epoch: 10 [51200/60000(85%)]\tTrain Loss: 0.147457\n",
      "Train Epoch: 10 [57600/60000(96%)]\tTrain Loss: 0.053007\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0027, \tTest Accuracy: 97.42 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''10. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy를 확인하기'''\n",
    "\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    \n",
    "    # 정의한 train 함수 실행\n",
    "    # model은 기존에 정의한 MLP 모델, train_loader는 학습 데이터, optimizer는 SGD,\n",
    "    # log_interval은 학습이 진행되면서 Mini-Batch의 Index를 이용해 과정을 모니터링할 수 있도록 출력하는 것을 의미함. \n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    \n",
    "    # 각 Epoch별로 출력되는 Loss 값과 accuracy 값을 계산함. \n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".\n",
    "         format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2214027",
   "metadata": {},
   "source": [
    "- sigmoid() 함수를 적용했을 때보다 ReLU() 함수를 적용했을 때 학습 시작부터 높은 성능을 유지하며 학습이 진행될수록 점점 성능이 높아지는 것을 확인할 수 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a76c412",
   "metadata": {},
   "source": [
    "## Reference\n",
    "---\n",
    "- 파이썬 딥러닝 파이토치 - 이경택, 방성수, 안상준"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
